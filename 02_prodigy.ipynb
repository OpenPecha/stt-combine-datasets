{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from prodigy instance\n",
    "\n",
    "The AWS EC2 instance where we used to run Prodigy is at prodigy.bdrc.io \n",
    "The instance has all the data before we moved to stt.pecha.tools\n",
    "Only the Quality Control team has worked on the prodigy instance recently to review all task on prodigy.\n",
    "\n",
    "To load data form prodigy, log into the server\n",
    "> ssh spsither@prodigy.bdrc.io\n",
    "\n",
    "Run the following script to export all the data from prodigy to jsonl files\n",
    ">/home/spsither/staging/export_all.sh\n",
    "\n",
    "Create a tar with all the jsonl files\n",
    ">tar -cJvf staging.tar staging/*.jsonl\n",
    "\n",
    "---\n",
    "\n",
    "Task that has been transcribed or reviewed but not finalised by the final reviewer are imported in stt.pecha.tools in `prodigy` group. When using data from staging.tar use only the finale_df all others will be in 01_stt_pecha_tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring the tar file from the server to the local machine\n",
    "! scp spsither@prodigy.bdrc.io:/home/spsither/staging.tar data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the tar file\n",
    "! tar -xf data/staging.tar -C data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def read_jsonl(filename):\n",
    "    df = pd.read_json(filename,lines=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "jsonl_directory = \"data/staging/\"\n",
    "\n",
    "files = os.listdir(jsonl_directory)\n",
    "\n",
    "pattern = \"jsonl\"\n",
    "files_matching_pattern = [file for file in files if file.endswith(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all reviewed files \n",
    "reviewed_jsonl_files = []\n",
    "for file in files_matching_pattern:\n",
    "    if 'review' in file and not 'stt_second_review' in file:\n",
    "        reviewed_jsonl_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all un-reviewed files\n",
    "transcribed_jsonl_files = []\n",
    "for file in files_matching_pattern:\n",
    "    if 'review' not in file and not 'stt_second_review' in file:\n",
    "        transcribed_jsonl_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tqdm\n",
    "! pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all the transcribed dataFrames\n",
    "temp = pd.DataFrame([])\n",
    "from tqdm.auto import tqdm\n",
    "for file in tqdm(transcribed_jsonl_files):\n",
    "    df = read_jsonl(f\"{jsonl_directory}/{file}\")\n",
    "    temp = pd.concat([temp,df],axis=0)\n",
    "    transcribed_df = temp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all the reviewed dataFrames\n",
    "from tqdm.auto import tqdm\n",
    "temp = pd.DataFrame([])\n",
    "for file in tqdm(reviewed_jsonl_files):\n",
    "    df = read_jsonl(f\"{jsonl_directory}/{file}\")\n",
    "    temp = pd.concat([temp,df],axis=0)\n",
    "    reviewed_df = temp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finale_df = read_jsonl(f\"{jsonl_directory}/stt_second_review.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_df['id'].fillna(transcribed_df['text'], inplace=True)\n",
    "reviewed_df['id'].fillna(reviewed_df['text'], inplace=True)\n",
    "finale_df['id'].fillna(finale_df['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_extensions = ['.mp3', '.wav', '.MP3', '.WAV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio_extension in audio_extensions:\n",
    "    transcribed_df['id'] = transcribed_df['id'].str.replace(audio_extension, '')\n",
    "    reviewed_df['id'] = reviewed_df['id'].str.replace(audio_extension, '')\n",
    "    finale_df['id'] = finale_df['id'].str.replace(audio_extension, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transcribed_df),len(reviewed_df),len(finale_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(transcribed_df['id'])), len(set(reviewed_df['id'])), len(set(finale_df['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 - len(set(transcribed_df['id'])) / len(transcribed_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_df.shape[0], reviewed_df.shape[0], finale_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_df.drop_duplicates(subset='id', keep=\"first\", inplace=True)\n",
    "reviewed_df.drop_duplicates(subset='id', keep=\"first\", inplace=True)\n",
    "finale_df.drop_duplicates(subset='id', keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_df.shape[0], reviewed_df.shape[0], finale_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transcribed_df),len(reviewed_df),len(finale_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_df = transcribed_df[transcribed_df['answer'] == 'accept']\n",
    "reviewed_df = reviewed_df[reviewed_df['answer'] == 'accept']\n",
    "finale_df = finale_df[finale_df['answer'] == 'accept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transcribed_df),len(reviewed_df),len(finale_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leakage check\n",
    "len(transcribed_df) - len(finale_df), len(transcribed_df) - len(reviewed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left side intersection\n",
    "intersection = reviewed_df.merge(finale_df, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection['grade'] = 1 # 1 means the task is transcribed only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection.loc[~intersection['transcript_x'].isna(), 'grade'] = 2 # 2 means the task is reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection.loc[~intersection['transcript_y'].isna(), 'grade'] = 3 # 3 means the task is reviewed twice by the qc team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection['transcript_y'].fillna(intersection['transcript_x'], inplace=True) # overwrite the transcribed text with the reviewed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = intersection[~intersection['transcript_y'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = intersection[['transcript_y', 'id', 'grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection['url'] = 'https://d38pmlk0v88drf.cloudfront.net/wav/' + intersection['id'] + '.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11001\n",
    "intersection.loc[i]['transcript_y'], intersection.loc[i,'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection['dept'] = intersection['id'].str[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection.groupby('dept').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection.rename(columns={\"id\": \"file_name\", \"transcript_y\": \"uni\", \"url\": \"url\", \"dept\": \"dept\", \"grade\": \"grade\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_intersection = intersection[['file_name', 'uni', 'url', 'dept', 'grade']]\n",
    "last_intersection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_intersection.to_csv('02_prodigy.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_intersection[last_intersection['file_name'] == 'STT_AB00001_0029_150584_to_151748']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
