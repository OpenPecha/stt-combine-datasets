{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from prodigy instance\n",
    "\n",
    "The AWS EC2 instance where we used to run Prodigy is at prodigy.bdrc.io \n",
    "The instance has all the data before we moved to stt.pecha.tools\n",
    "Only the Quality Control team has worked on the prodigy instance recently to review all task on prodigy.\n",
    "\n",
    "To load data form prodigy, log into the server\n",
    "> ssh spsither@prodigy.bdrc.io\n",
    "\n",
    "Run the following script to export all the data from prodigy to jsonl files\n",
    ">/home/spsither/staging/export_all.sh\n",
    "\n",
    "Create a tar with all the jsonl files\n",
    ">tar -cJvf staging.tar staging/*.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring the tar file from the server to the local machine\n",
    "! scp spsither@prodigy.bdrc.io:/home/spsither/staging.tar data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the tar file\n",
    "! tar -xf data/staging.tar -C data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def read_jsonl(filename):\n",
    "    df = pd.read_json(filename,lines=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "jsonl_directory = \"data/staging/\"\n",
    "\n",
    "files = os.listdir(jsonl_directory)\n",
    "\n",
    "pattern = \"jsonl\"\n",
    "files_matching_pattern = [file for file in files if file.endswith(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all reviewed files \n",
    "reviewed_jsonl_files = []\n",
    "for file in files_matching_pattern:\n",
    "    if 'review' in file and not 'stt_second_review' in file:\n",
    "        reviewed_jsonl_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all un-reviewed files\n",
    "transcribed_jsonl_files = []\n",
    "for file in files_matching_pattern:\n",
    "    if 'review' not in file and not 'stt_second_review' in file:\n",
    "        transcribed_jsonl_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tqdm\n",
    "! pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all the transcribed dataFrames\n",
    "temp = pd.DataFrame([])\n",
    "from tqdm.auto import tqdm\n",
    "for file in tqdm(transcribed_jsonl_files):\n",
    "    df = read_jsonl(f\"{jsonl_directory}/{file}\")\n",
    "    temp = pd.concat([temp,df],axis=0)\n",
    "    transcribed_df = temp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all the reviewed dataFrames\n",
    "from tqdm.auto import tqdm\n",
    "temp = pd.DataFrame([])\n",
    "for file in tqdm(reviewed_jsonl_files):\n",
    "    df = read_jsonl(f\"{jsonl_directory}/{file}\")\n",
    "    temp = pd.concat([temp,df],axis=0)\n",
    "    reviewed_df = temp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finale_df = read_jsonl(f\"{jsonl_directory}/stt_second_review.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_df['id'].fillna(transcribed_df['text'], inplace=True)\n",
    "reviewed_df['id'].fillna(reviewed_df['text'], inplace=True)\n",
    "finale_df['id'].fillna(finale_df['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_extensions = ['.mp3', '.wav', '.MP3', '.WAV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio_extension in audio_extensions:\n",
    "    transcribed_df['id'] = transcribed_df['id'].str.replace(audio_extension, '')\n",
    "    reviewed_df['id'] = reviewed_df['id'].str.replace(audio_extension, '')\n",
    "    finale_df['id'] = finale_df['id'].str.replace(audio_extension, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transcribed_df),len(reviewed_df),len(finale_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(transcribed_df['id'])), len(set(reviewed_df['id'])), len(set(finale_df['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 - len(set(transcribed_df['id'])) / len(transcribed_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_df.shape[0], reviewed_df.shape[0], finale_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_df.drop_duplicates(subset='id', keep=\"first\", inplace=True)\n",
    "reviewed_df.drop_duplicates(subset='id', keep=\"first\", inplace=True)\n",
    "finale_df.drop_duplicates(subset='id', keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_df.shape[0], reviewed_df.shape[0], finale_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transcribed_df),len(reviewed_df),len(finale_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_df = transcribed_df[transcribed_df['answer'] == 'accept']\n",
    "reviewed_df = reviewed_df[reviewed_df['answer'] == 'accept']\n",
    "finale_df = finale_df[finale_df['answer'] == 'accept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transcribed_df),len(reviewed_df),len(finale_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leakage check\n",
    "len(transcribed_df) - len(finale_df), len(transcribed_df) - len(reviewed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left side intersection\n",
    "intersection = reviewed_df.merge(finale_df, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection['grade'] = 1 # 1 means the task is transcribed only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection.loc[~intersection['transcript_x'].isna(), 'grade'] = 2 # 2 means the task is reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection.loc[~intersection['transcript_y'].isna(), 'grade'] = 3 # 3 means the task is reviewed twice by the qc team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection['transcript_y'].fillna(intersection['transcript_x'], inplace=True) # overwrite the transcribed text with the reviewed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = intersection[~intersection['transcript_y'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = intersection[['transcript_y', 'id', 'grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection['url'] = 'https://d38pmlk0v88drf.cloudfront.net/wav/' + intersection['id'] + '.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11001\n",
    "intersection.loc[i]['transcript_y'], intersection.loc[i,'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection['dept'] = intersection['id'].str[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection.groupby('dept').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection.rename(columns={\"id\": \"file_name\", \"transcript_y\": \"uni\", \"url\": \"url\", \"dept\": \"dept\", \"grade\": \"grade\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_intersection = intersection[['file_name', 'uni', 'url', 'dept', 'grade']]\n",
    "last_intersection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_intersection.to_csv('02_prodigy.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_intersection[last_intersection['file_name'] == 'STT_AB00001_0029_150584_to_151748']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('02_prodigy_finalised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374548"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>len</th>\n",
       "      <th>dept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STT_TT00001_00233.450-00233.950</td>\n",
       "      <td>དེ་འདྲ་ཡིན་དུས་</td>\n",
       "      <td>15</td>\n",
       "      <td>STT_TT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STT_TT00001_00328.100-00329.300</td>\n",
       "      <td>ཨེ། དཔལ་མགོན་འཕགས་པ་ཀླུ་སྒྲུབ་ཀི་</td>\n",
       "      <td>33</td>\n",
       "      <td>STT_TT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STT_TT00001_00083.000-00083.750</td>\n",
       "      <td>ཉིན་རེ་ཉིན་རེའི།</td>\n",
       "      <td>16</td>\n",
       "      <td>STT_TT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STT_TT00001_00240.650-00241.550</td>\n",
       "      <td>འདིའི་གོང་ལ།</td>\n",
       "      <td>12</td>\n",
       "      <td>STT_TT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STT_TT00001_00102.350-00103.700</td>\n",
       "      <td>ཨེ་ནས་ཅིག་སེམས་འཁྲུགས་བསྡད་ཡ།</td>\n",
       "      <td>29</td>\n",
       "      <td>STT_TT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id                         transcript  len  \\\n",
       "0  STT_TT00001_00233.450-00233.950                    དེ་འདྲ་ཡིན་དུས་   15   \n",
       "1  STT_TT00001_00328.100-00329.300  ཨེ། དཔལ་མགོན་འཕགས་པ་ཀླུ་སྒྲུབ་ཀི་   33   \n",
       "2  STT_TT00001_00083.000-00083.750                   ཉིན་རེ་ཉིན་རེའི།   16   \n",
       "3  STT_TT00001_00240.650-00241.550                       འདིའི་གོང་ལ།   12   \n",
       "4  STT_TT00001_00102.350-00103.700      ཨེ་ནས་ཅིག་སེམས་འཁྲུགས་བསྡད་ཡ།   29   \n",
       "\n",
       "     dept  \n",
       "0  STT_TT  \n",
       "1  STT_TT  \n",
       "2  STT_TT  \n",
       "3  STT_TT  \n",
       "4  STT_TT  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5900000000001455"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getTimeSpan(filename):\n",
    "\n",
    "    filename = filename.replace(\".wav\", \"\")\n",
    "    filename = filename.replace(\".WAV\", \"\")\n",
    "    filename = filename.replace(\".mp3\", \"\")\n",
    "    filename = filename.replace(\".MP3\", \"\")\n",
    "    try:\n",
    "        if \"_to_\" in filename:\n",
    "            start, end = filename.split(\"_to_\")\n",
    "            start = start.split(\"_\")[-1]\n",
    "            end = end.split(\"_\")[0]\n",
    "            end = float(end)\n",
    "            start = float(start)\n",
    "            return abs(end - start)/1000\n",
    "        else:\n",
    "            start, end = filename.split(\"-\")\n",
    "            start = start.split(\"_\")[-1]\n",
    "            end = end.split(\"_\")[0]\n",
    "            end =   float(end)\n",
    "            start = float(start)\n",
    "            return abs(end - start)\n",
    "    except Exception as err:\n",
    "        print(f\"filename is:'{filename}'. Could not parse to get time span.\")\n",
    "        return 0\n",
    "    \n",
    "\n",
    "getTimeSpan(\"STT_TT00031_03471.850-03477.44\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['audio_len'] = df['id'].apply(getTimeSpan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307.3489561111112"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['audio_len'].sum()/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
